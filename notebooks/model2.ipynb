{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "# import keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   popularity  duration_ms  explicit  danceability  energy  key  loudness   \n0          34       247707         0         0.491   0.606    7   -10.172  \\\n1          34       247707         0         0.491   0.606    7   -10.172   \n2          34       247707         0         0.491   0.606    7   -10.172   \n3          35       140067         0         0.449   0.749    9    -8.585   \n4          35       140067         0         0.449   0.749    9    -8.585   \n\n   speechiness  acousticness  instrumentalness  liveness  valence    tempo   \n0       0.0377       0.00327          0.000008     0.341    0.669  123.025  \\\n1       0.0377       0.00327          0.000008     0.341    0.669  123.025   \n2       0.0377       0.00327          0.000008     0.341    0.669  123.025   \n3       0.0775       0.01000          0.000000     0.391    0.448  106.861   \n4       0.0775       0.01000          0.000000     0.391    0.448  106.861   \n\n                                    favourite_genres   \n0                   [permanent wave, mandopop, funk]  \\\n1                    [filmi, regional mexican, folk]   \n2  [psychedelic rock, country rock, rock en espanol]   \n3  [psychedelic rock, country rock, rock en espanol]   \n4  [psychedelic rock, country rock, rock en espanol]   \n\n                                              genres  skipped   \n0  [album rock, art rock, classic rock, folk rock...    False  \\\n1  [album rock, art rock, classic rock, folk rock...    False   \n2  [album rock, art rock, classic rock, folk rock...    False   \n3  [album rock, art rock, classic rock, folk rock...    False   \n4  [album rock, art rock, classic rock, folk rock...    False   \n\n   number_of_matching_genres  \n0                          0  \n1                          0  \n2                          1  \n3                          1  \n4                          1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>popularity</th>\n      <th>duration_ms</th>\n      <th>explicit</th>\n      <th>danceability</th>\n      <th>energy</th>\n      <th>key</th>\n      <th>loudness</th>\n      <th>speechiness</th>\n      <th>acousticness</th>\n      <th>instrumentalness</th>\n      <th>liveness</th>\n      <th>valence</th>\n      <th>tempo</th>\n      <th>favourite_genres</th>\n      <th>genres</th>\n      <th>skipped</th>\n      <th>number_of_matching_genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>34</td>\n      <td>247707</td>\n      <td>0</td>\n      <td>0.491</td>\n      <td>0.606</td>\n      <td>7</td>\n      <td>-10.172</td>\n      <td>0.0377</td>\n      <td>0.00327</td>\n      <td>0.000008</td>\n      <td>0.341</td>\n      <td>0.669</td>\n      <td>123.025</td>\n      <td>[permanent wave, mandopop, funk]</td>\n      <td>[album rock, art rock, classic rock, folk rock...</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>34</td>\n      <td>247707</td>\n      <td>0</td>\n      <td>0.491</td>\n      <td>0.606</td>\n      <td>7</td>\n      <td>-10.172</td>\n      <td>0.0377</td>\n      <td>0.00327</td>\n      <td>0.000008</td>\n      <td>0.341</td>\n      <td>0.669</td>\n      <td>123.025</td>\n      <td>[filmi, regional mexican, folk]</td>\n      <td>[album rock, art rock, classic rock, folk rock...</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>34</td>\n      <td>247707</td>\n      <td>0</td>\n      <td>0.491</td>\n      <td>0.606</td>\n      <td>7</td>\n      <td>-10.172</td>\n      <td>0.0377</td>\n      <td>0.00327</td>\n      <td>0.000008</td>\n      <td>0.341</td>\n      <td>0.669</td>\n      <td>123.025</td>\n      <td>[psychedelic rock, country rock, rock en espanol]</td>\n      <td>[album rock, art rock, classic rock, folk rock...</td>\n      <td>False</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35</td>\n      <td>140067</td>\n      <td>0</td>\n      <td>0.449</td>\n      <td>0.749</td>\n      <td>9</td>\n      <td>-8.585</td>\n      <td>0.0775</td>\n      <td>0.01000</td>\n      <td>0.000000</td>\n      <td>0.391</td>\n      <td>0.448</td>\n      <td>106.861</td>\n      <td>[psychedelic rock, country rock, rock en espanol]</td>\n      <td>[album rock, art rock, classic rock, folk rock...</td>\n      <td>False</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>35</td>\n      <td>140067</td>\n      <td>0</td>\n      <td>0.449</td>\n      <td>0.749</td>\n      <td>9</td>\n      <td>-8.585</td>\n      <td>0.0775</td>\n      <td>0.01000</td>\n      <td>0.000000</td>\n      <td>0.391</td>\n      <td>0.448</td>\n      <td>106.861</td>\n      <td>[psychedelic rock, country rock, rock en espanol]</td>\n      <td>[album rock, art rock, classic rock, folk rock...</td>\n      <td>False</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data_path = '../data/merged_data.jsonl'\n",
    "data = pd.read_json(merged_data_path, lines=True)\n",
    "\n",
    "# data = data.drop(\n",
    "#     columns=[\"release_date\", \"key\", \"loudness\",\n",
    "#              \"explicit\", \"popularity\", \"duration_ms\", \"danceability\", \"energy\", \"speechiness\",\n",
    "#              \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\", \"tempo\"])\n",
    "\n",
    "data = data.drop(\n",
    "    columns=[\"release_date\", \"name\"])\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_favourite_genres 46\n",
      "unique_genres 46\n",
      "common genres {'blues rock', 'singer-songwriter', 'pop', 'quiet storm', 'album rock', 'ranchera', 'motown', 'vocal jazz', 'classic rock', 'soul', 'art rock', 'pop rock', 'folk', 'lounge', 'j-pop', 'filmi', 'hard rock', 'new wave', 'mellow gold', 'country rock', 'new romantic', 'permanent wave', 'alternative rock', 'new wave pop', 'latin alternative', 'soft rock', 'rock en espanol', 'brill building pop', 'c-pop', 'adult standards', 'alternative metal', 'mpb', 'turkish pop', 'metal', 'funk', 'europop', 'latin', 'latin pop', 'latin rock', 'tropical', 'rock', 'psychedelic rock', 'hoerspiel', 'dance pop', 'mandopop', 'regional mexican'}\n"
     ]
    },
    {
     "data": {
      "text/plain": "   popularity  duration_ms  explicit  danceability  energy  key  loudness   \n0          34       247707         0         0.491   0.606    7   -10.172  \\\n1          34       247707         0         0.491   0.606    7   -10.172   \n2          34       247707         0         0.491   0.606    7   -10.172   \n3          35       140067         0         0.449   0.749    9    -8.585   \n4          35       140067         0         0.449   0.749    9    -8.585   \n\n   speechiness  acousticness  instrumentalness  liveness  valence    tempo   \n0       0.0377       0.00327          0.000008     0.341    0.669  123.025  \\\n1       0.0377       0.00327          0.000008     0.341    0.669  123.025   \n2       0.0377       0.00327          0.000008     0.341    0.669  123.025   \n3       0.0775       0.01000          0.000000     0.391    0.448  106.861   \n4       0.0775       0.01000          0.000000     0.391    0.448  106.861   \n\n                                    favourite_genres   \n0                   [permanent wave, mandopop, funk]  \\\n1                    [filmi, regional mexican, folk]   \n2  [psychedelic rock, country rock, rock en espanol]   \n3  [psychedelic rock, country rock, rock en espanol]   \n4  [psychedelic rock, country rock, rock en espanol]   \n\n                                              genres  skipped   \n0  [album rock, art rock, classic rock, psychedel...    False  \\\n1  [album rock, art rock, classic rock, psychedel...    False   \n2  [album rock, art rock, classic rock, psychedel...    False   \n3  [album rock, art rock, classic rock, psychedel...    False   \n4  [album rock, art rock, classic rock, psychedel...    False   \n\n   number_of_matching_genres  \n0                          0  \n1                          0  \n2                          1  \n3                          1  \n4                          1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>popularity</th>\n      <th>duration_ms</th>\n      <th>explicit</th>\n      <th>danceability</th>\n      <th>energy</th>\n      <th>key</th>\n      <th>loudness</th>\n      <th>speechiness</th>\n      <th>acousticness</th>\n      <th>instrumentalness</th>\n      <th>liveness</th>\n      <th>valence</th>\n      <th>tempo</th>\n      <th>favourite_genres</th>\n      <th>genres</th>\n      <th>skipped</th>\n      <th>number_of_matching_genres</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>34</td>\n      <td>247707</td>\n      <td>0</td>\n      <td>0.491</td>\n      <td>0.606</td>\n      <td>7</td>\n      <td>-10.172</td>\n      <td>0.0377</td>\n      <td>0.00327</td>\n      <td>0.000008</td>\n      <td>0.341</td>\n      <td>0.669</td>\n      <td>123.025</td>\n      <td>[permanent wave, mandopop, funk]</td>\n      <td>[album rock, art rock, classic rock, psychedel...</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>34</td>\n      <td>247707</td>\n      <td>0</td>\n      <td>0.491</td>\n      <td>0.606</td>\n      <td>7</td>\n      <td>-10.172</td>\n      <td>0.0377</td>\n      <td>0.00327</td>\n      <td>0.000008</td>\n      <td>0.341</td>\n      <td>0.669</td>\n      <td>123.025</td>\n      <td>[filmi, regional mexican, folk]</td>\n      <td>[album rock, art rock, classic rock, psychedel...</td>\n      <td>False</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>34</td>\n      <td>247707</td>\n      <td>0</td>\n      <td>0.491</td>\n      <td>0.606</td>\n      <td>7</td>\n      <td>-10.172</td>\n      <td>0.0377</td>\n      <td>0.00327</td>\n      <td>0.000008</td>\n      <td>0.341</td>\n      <td>0.669</td>\n      <td>123.025</td>\n      <td>[psychedelic rock, country rock, rock en espanol]</td>\n      <td>[album rock, art rock, classic rock, psychedel...</td>\n      <td>False</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35</td>\n      <td>140067</td>\n      <td>0</td>\n      <td>0.449</td>\n      <td>0.749</td>\n      <td>9</td>\n      <td>-8.585</td>\n      <td>0.0775</td>\n      <td>0.01000</td>\n      <td>0.000000</td>\n      <td>0.391</td>\n      <td>0.448</td>\n      <td>106.861</td>\n      <td>[psychedelic rock, country rock, rock en espanol]</td>\n      <td>[album rock, art rock, classic rock, psychedel...</td>\n      <td>False</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>35</td>\n      <td>140067</td>\n      <td>0</td>\n      <td>0.449</td>\n      <td>0.749</td>\n      <td>9</td>\n      <td>-8.585</td>\n      <td>0.0775</td>\n      <td>0.01000</td>\n      <td>0.000000</td>\n      <td>0.391</td>\n      <td>0.448</td>\n      <td>106.861</td>\n      <td>[psychedelic rock, country rock, rock en espanol]</td>\n      <td>[album rock, art rock, classic rock, psychedel...</td>\n      <td>False</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_favourite_genres = set()\n",
    "for genres in data['favourite_genres']:\n",
    "  for genre in genres:\n",
    "    unique_favourite_genres.add(genre)\n",
    "\n",
    "unique_genres = set()\n",
    "for genres in data['genres']:\n",
    "  for genre in genres:\n",
    "    unique_genres.add(genre)\n",
    "\n",
    "# show all common genres between all favourite_genres and genres\n",
    "print(\"unique_favourite_genres\", len(unique_favourite_genres))\n",
    "print(\"unique_genres\", len(unique_genres))\n",
    "common_genres = unique_favourite_genres.intersection(unique_genres)\n",
    "print(\"common genres\", common_genres)\n",
    "\n",
    "# remove genres that are not in common_genres\n",
    "data['genres'] = data['genres'].apply(\n",
    "    lambda x: [genre for genre in x if genre in common_genres])\n",
    "\n",
    "data.head()\n",
    "\n",
    "# TODO remove ??? moze niepotrzebne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   popularity  popularity_normalized  duration_ms  duration_ms_normalized   \n0          34               0.354167       247707                0.092836  \\\n1          34               0.354167       247707                0.092836   \n2          34               0.354167       247707                0.092836   \n3          35               0.364583       140067                0.046724   \n4          35               0.364583       140067                0.046724   \n\n   skipped  \n0    False  \n1    False  \n2    False  \n3    False  \n4    False  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>popularity</th>\n      <th>popularity_normalized</th>\n      <th>duration_ms</th>\n      <th>duration_ms_normalized</th>\n      <th>skipped</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>34</td>\n      <td>0.354167</td>\n      <td>247707</td>\n      <td>0.092836</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>34</td>\n      <td>0.354167</td>\n      <td>247707</td>\n      <td>0.092836</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>34</td>\n      <td>0.354167</td>\n      <td>247707</td>\n      <td>0.092836</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35</td>\n      <td>0.364583</td>\n      <td>140067</td>\n      <td>0.046724</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>35</td>\n      <td>0.364583</td>\n      <td>140067</td>\n      <td>0.046724</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine genres and favourite_genres\n",
    "all_genres = list(data['favourite_genres'] + data['genres'])\n",
    "\n",
    "# One-hot encode the genres\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(all_genres)\n",
    "\n",
    "encoded_all_genres = mlb.fit_transform(all_genres)\n",
    "\n",
    "# Split encoded_genres into genres and favourite_genres\n",
    "# encoded_favourite_genres = encoded_all_genres[:, :len(data['favourite_genres'][0])]\n",
    "# encoded_genres = encoded_all_genres[:, len(data['favourite_genres'][0]):]\n",
    "\n",
    "encoded_favourite_genres = mlb.transform(data['favourite_genres'])\n",
    "encoded_genres = mlb.transform(data['genres'])\n",
    "\n",
    "popularity_normalized = data['popularity'].values.reshape(-1, 1)\n",
    "popularity_normalized = (popularity_normalized - np.min(popularity_normalized)) / (np.max(popularity_normalized) - np.min(popularity_normalized))\n",
    "\n",
    "duration_ms_normalized = data['duration_ms'].values.reshape(-1, 1)\n",
    "duration_ms_normalized = (duration_ms_normalized - np.min(duration_ms_normalized)) / (np.max(duration_ms_normalized) - np.min(duration_ms_normalized))\n",
    "\n",
    "# create data frame from data genres, data favourite_genres, encoded genres, encoded favourite_genres\n",
    "df = pd.DataFrame(\n",
    "  data={'popularity': data['popularity'], 'popularity_normalized': popularity_normalized.reshape(-1),\n",
    "        'duration_ms': data['duration_ms'], 'duration_ms_normalized': duration_ms_normalized.reshape(-1),\n",
    "        'skipped': data['skipped']})\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "    0    1    2    3    4    5    6    7    8    9   ...   84   85   86   87   \n0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  1.0  0.0  0.0  0.0  \\\n1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  1.0  0.0  0.0  0.0   \n2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  1.0  0.0  0.0  0.0   \n3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  1.0  0.0  0.0  0.0   \n4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  1.0  0.0  0.0  0.0   \n\n    88   89   90   91        92        93  \n0  0.0  0.0  0.0  0.0  0.354167  0.092836  \n1  0.0  0.0  0.0  0.0  0.354167  0.092836  \n2  0.0  0.0  0.0  0.0  0.354167  0.092836  \n3  0.0  0.0  0.0  0.0  0.364583  0.046724  \n4  0.0  0.0  0.0  0.0  0.364583  0.046724  \n\n[5 rows x 94 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>84</th>\n      <th>85</th>\n      <th>86</th>\n      <th>87</th>\n      <th>88</th>\n      <th>89</th>\n      <th>90</th>\n      <th>91</th>\n      <th>92</th>\n      <th>93</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.354167</td>\n      <td>0.092836</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.354167</td>\n      <td>0.092836</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.354167</td>\n      <td>0.092836</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.364583</td>\n      <td>0.046724</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.364583</td>\n      <td>0.046724</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 94 columns</p>\n</div>"
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO uzywac keras tokenizer?\n",
    "\n",
    "# Concatenate the one-hot encoded columns\n",
    "X = np.concatenate([encoded_favourite_genres, encoded_genres, popularity_normalized, duration_ms_normalized], axis=1)\n",
    "# X = np.concatenate([popularity_normalized, duration_ms_normalized], axis=1)\n",
    "\n",
    "# create df from X\n",
    "# df = pd.DataFrame(data=X)\n",
    "# df.head(5)\n",
    "#\n",
    "# Extract the labels\n",
    "y = data['skipped'].astype(int).values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "# count skipped and not skipped songs in X_train\n",
    "print(\"Y_train not skipped\", np.count_nonzero(y_test == 0))\n",
    "print(\"Y_train skipped\", np.count_nonzero(y_test == 1))\n",
    "print(\"Y_train skipped %\", np.count_nonzero(y_test == 1) / len(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "  model = Sequential()\n",
    "  model.add(Dense(32 * 2, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(32, activation='relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  # model.add(Dense(1000, activation='relu'))\n",
    "  # model.add(Dropout(0.5))\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "  # model.compile(\n",
    "  #     optimizer=keras.optimizers.Adam(hp.Choice('learning_date', values=[0.5, 0.1, 0.01])),\n",
    "  #     loss='binary_crossentropy', metrics=['accuracy'])\n",
    "  model.compile(\n",
    "      optimizer=Adam(),\n",
    "      loss='binary_crossentropy', metrics=['accuracy'])\n",
    "  return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "247/247 - 3s - loss: 0.6094 - accuracy: 0.6704 - val_loss: 0.5711 - val_accuracy: 0.6889 - 3s/epoch - 13ms/step\n",
      "Epoch 2/50\n",
      "247/247 - 3s - loss: 0.5832 - accuracy: 0.6862 - val_loss: 0.5516 - val_accuracy: 0.6945 - 3s/epoch - 10ms/step\n",
      "Epoch 3/50\n",
      "247/247 - 3s - loss: 0.5783 - accuracy: 0.6941 - val_loss: 0.5529 - val_accuracy: 0.6990 - 3s/epoch - 11ms/step\n",
      "Epoch 4/50\n",
      "247/247 - 3s - loss: 0.5739 - accuracy: 0.6979 - val_loss: 0.5516 - val_accuracy: 0.6950 - 3s/epoch - 10ms/step\n",
      "Epoch 5/50\n",
      "247/247 - 3s - loss: 0.5680 - accuracy: 0.7051 - val_loss: 0.5610 - val_accuracy: 0.7056 - 3s/epoch - 10ms/step\n",
      "Epoch 6/50\n",
      "247/247 - 3s - loss: 0.5649 - accuracy: 0.7033 - val_loss: 0.5550 - val_accuracy: 0.6985 - 3s/epoch - 11ms/step\n",
      "Epoch 7/50\n",
      "247/247 - 3s - loss: 0.5618 - accuracy: 0.7056 - val_loss: 0.5536 - val_accuracy: 0.7026 - 3s/epoch - 10ms/step\n",
      "Epoch 8/50\n",
      "247/247 - 3s - loss: 0.5554 - accuracy: 0.7064 - val_loss: 0.5599 - val_accuracy: 0.6960 - 3s/epoch - 11ms/step\n",
      "Epoch 9/50\n",
      "247/247 - 3s - loss: 0.5524 - accuracy: 0.7142 - val_loss: 0.5600 - val_accuracy: 0.6940 - 3s/epoch - 11ms/step\n",
      "Epoch 10/50\n",
      "247/247 - 3s - loss: 0.5449 - accuracy: 0.7143 - val_loss: 0.5638 - val_accuracy: 0.7036 - 3s/epoch - 11ms/step\n",
      "Epoch 11/50\n",
      "247/247 - 3s - loss: 0.5450 - accuracy: 0.7236 - val_loss: 0.5547 - val_accuracy: 0.7026 - 3s/epoch - 11ms/step\n",
      "Epoch 12/50\n",
      "247/247 - 3s - loss: 0.5350 - accuracy: 0.7262 - val_loss: 0.5792 - val_accuracy: 0.6950 - 3s/epoch - 11ms/step\n",
      "Epoch 13/50\n",
      "247/247 - 3s - loss: 0.5331 - accuracy: 0.7275 - val_loss: 0.5725 - val_accuracy: 0.6955 - 3s/epoch - 11ms/step\n",
      "Epoch 14/50\n",
      "247/247 - 3s - loss: 0.5293 - accuracy: 0.7258 - val_loss: 0.5626 - val_accuracy: 0.6930 - 3s/epoch - 11ms/step\n",
      "Epoch 15/50\n",
      "247/247 - 3s - loss: 0.5227 - accuracy: 0.7330 - val_loss: 0.5682 - val_accuracy: 0.7006 - 3s/epoch - 11ms/step\n",
      "Epoch 16/50\n",
      "247/247 - 3s - loss: 0.5168 - accuracy: 0.7357 - val_loss: 0.5715 - val_accuracy: 0.7071 - 3s/epoch - 10ms/step\n",
      "Epoch 17/50\n",
      "247/247 - 3s - loss: 0.5137 - accuracy: 0.7422 - val_loss: 0.5771 - val_accuracy: 0.7016 - 3s/epoch - 11ms/step\n",
      "Epoch 18/50\n",
      "247/247 - 3s - loss: 0.5105 - accuracy: 0.7398 - val_loss: 0.5802 - val_accuracy: 0.6955 - 3s/epoch - 11ms/step\n",
      "Epoch 19/50\n",
      "247/247 - 3s - loss: 0.5066 - accuracy: 0.7451 - val_loss: 0.5926 - val_accuracy: 0.7041 - 3s/epoch - 12ms/step\n",
      "Epoch 20/50\n",
      "247/247 - 3s - loss: 0.5007 - accuracy: 0.7460 - val_loss: 0.5892 - val_accuracy: 0.6925 - 3s/epoch - 12ms/step\n",
      "Epoch 21/50\n",
      "247/247 - 3s - loss: 0.4963 - accuracy: 0.7473 - val_loss: 0.5954 - val_accuracy: 0.6960 - 3s/epoch - 11ms/step\n",
      "Epoch 22/50\n",
      "247/247 - 3s - loss: 0.4905 - accuracy: 0.7510 - val_loss: 0.6050 - val_accuracy: 0.6950 - 3s/epoch - 12ms/step\n",
      "Epoch 23/50\n",
      "247/247 - 3s - loss: 0.4909 - accuracy: 0.7475 - val_loss: 0.5960 - val_accuracy: 0.6970 - 3s/epoch - 12ms/step\n",
      "Epoch 24/50\n",
      "247/247 - 3s - loss: 0.4845 - accuracy: 0.7520 - val_loss: 0.6004 - val_accuracy: 0.6950 - 3s/epoch - 12ms/step\n",
      "Epoch 25/50\n",
      "247/247 - 3s - loss: 0.4812 - accuracy: 0.7546 - val_loss: 0.6131 - val_accuracy: 0.6915 - 3s/epoch - 12ms/step\n",
      "Epoch 26/50\n",
      "247/247 - 3s - loss: 0.4776 - accuracy: 0.7566 - val_loss: 0.6319 - val_accuracy: 0.6793 - 3s/epoch - 12ms/step\n",
      "Epoch 27/50\n",
      "247/247 - 3s - loss: 0.4716 - accuracy: 0.7601 - val_loss: 0.6244 - val_accuracy: 0.6930 - 3s/epoch - 12ms/step\n",
      "Epoch 28/50\n",
      "247/247 - 3s - loss: 0.4728 - accuracy: 0.7591 - val_loss: 0.6292 - val_accuracy: 0.6899 - 3s/epoch - 11ms/step\n",
      "Epoch 29/50\n",
      "247/247 - 3s - loss: 0.4656 - accuracy: 0.7608 - val_loss: 0.6332 - val_accuracy: 0.6849 - 3s/epoch - 11ms/step\n",
      "Epoch 30/50\n",
      "247/247 - 3s - loss: 0.4648 - accuracy: 0.7649 - val_loss: 0.6453 - val_accuracy: 0.6884 - 3s/epoch - 11ms/step\n",
      "Epoch 31/50\n",
      "247/247 - 3s - loss: 0.4604 - accuracy: 0.7662 - val_loss: 0.6521 - val_accuracy: 0.6889 - 3s/epoch - 11ms/step\n",
      "Epoch 32/50\n",
      "247/247 - 3s - loss: 0.4579 - accuracy: 0.7647 - val_loss: 0.6481 - val_accuracy: 0.6920 - 3s/epoch - 11ms/step\n",
      "Epoch 33/50\n",
      "247/247 - 3s - loss: 0.4531 - accuracy: 0.7704 - val_loss: 0.6586 - val_accuracy: 0.6839 - 3s/epoch - 10ms/step\n",
      "Epoch 34/50\n",
      "247/247 - 3s - loss: 0.4548 - accuracy: 0.7668 - val_loss: 0.6619 - val_accuracy: 0.6849 - 3s/epoch - 11ms/step\n",
      "Epoch 35/50\n",
      "247/247 - 3s - loss: 0.4521 - accuracy: 0.7715 - val_loss: 0.6673 - val_accuracy: 0.6884 - 3s/epoch - 12ms/step\n",
      "Epoch 36/50\n",
      "247/247 - 3s - loss: 0.4458 - accuracy: 0.7701 - val_loss: 0.6665 - val_accuracy: 0.6859 - 3s/epoch - 10ms/step\n",
      "Epoch 37/50\n",
      "247/247 - 3s - loss: 0.4397 - accuracy: 0.7709 - val_loss: 0.6991 - val_accuracy: 0.6844 - 3s/epoch - 11ms/step\n",
      "Epoch 38/50\n",
      "247/247 - 3s - loss: 0.4430 - accuracy: 0.7751 - val_loss: 0.6907 - val_accuracy: 0.6904 - 3s/epoch - 11ms/step\n",
      "Epoch 39/50\n",
      "247/247 - 3s - loss: 0.4414 - accuracy: 0.7781 - val_loss: 0.6909 - val_accuracy: 0.6899 - 3s/epoch - 11ms/step\n",
      "Epoch 40/50\n",
      "247/247 - 3s - loss: 0.4353 - accuracy: 0.7756 - val_loss: 0.7232 - val_accuracy: 0.6909 - 3s/epoch - 11ms/step\n",
      "Epoch 41/50\n",
      "247/247 - 3s - loss: 0.4315 - accuracy: 0.7797 - val_loss: 0.7293 - val_accuracy: 0.6874 - 3s/epoch - 11ms/step\n",
      "Epoch 42/50\n",
      "247/247 - 3s - loss: 0.4366 - accuracy: 0.7781 - val_loss: 0.7083 - val_accuracy: 0.6930 - 3s/epoch - 10ms/step\n",
      "Epoch 43/50\n",
      "247/247 - 3s - loss: 0.4309 - accuracy: 0.7786 - val_loss: 0.7155 - val_accuracy: 0.6920 - 3s/epoch - 10ms/step\n",
      "Epoch 44/50\n",
      "247/247 - 3s - loss: 0.4301 - accuracy: 0.7772 - val_loss: 0.7267 - val_accuracy: 0.6884 - 3s/epoch - 10ms/step\n",
      "Epoch 45/50\n",
      "247/247 - 3s - loss: 0.4258 - accuracy: 0.7814 - val_loss: 0.7520 - val_accuracy: 0.6854 - 3s/epoch - 11ms/step\n",
      "Epoch 46/50\n",
      "247/247 - 3s - loss: 0.4317 - accuracy: 0.7796 - val_loss: 0.7397 - val_accuracy: 0.6844 - 3s/epoch - 11ms/step\n",
      "Epoch 47/50\n",
      "247/247 - 3s - loss: 0.4236 - accuracy: 0.7828 - val_loss: 0.7923 - val_accuracy: 0.6930 - 3s/epoch - 11ms/step\n",
      "Epoch 48/50\n",
      "247/247 - 3s - loss: 0.4278 - accuracy: 0.7838 - val_loss: 0.7678 - val_accuracy: 0.6889 - 3s/epoch - 11ms/step\n",
      "Epoch 49/50\n",
      "247/247 - 3s - loss: 0.4200 - accuracy: 0.7815 - val_loss: 0.7982 - val_accuracy: 0.6915 - 3s/epoch - 11ms/step\n",
      "Epoch 50/50\n",
      "247/247 - 3s - loss: 0.4228 - accuracy: 0.7823 - val_loss: 0.8142 - val_accuracy: 0.6925 - 3s/epoch - 10ms/step\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "batch_size = 32\n",
    "\n",
    "model = build_model(None)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# tuner = keras_tuner.tuners.Hyperband(\n",
    "#     build_model,\n",
    "#     objective='val_accuracy',\n",
    "#     max_epochs=50,\n",
    "#     max_trials=10,\n",
    "#     executions_per_trial=2,\n",
    "#     directory='my_dir')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner.search(\n",
    "#     (X_train, y_train),\n",
    "#     validation_data=(X_test, y_test),\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 - 0s - loss: 0.8142 - accuracy: 0.6925 - 224ms/epoch - 4ms/step\n",
      "Test set accuracy: 0.6924633383750916\n",
      "TEST\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "Accuracy: 0.6924633282751644\n",
      "Confusion matrix:\n",
      " [[1039  207]\n",
      " [ 401  330]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.83      0.77      1246\n",
      "           1       0.61      0.45      0.52       731\n",
      "\n",
      "    accuracy                           0.69      1977\n",
      "   macro avg       0.67      0.64      0.65      1977\n",
      "weighted avg       0.68      0.69      0.68      1977\n",
      "\n",
      "TRAIN\n",
      "247/247 [==============================] - 1s 2ms/step\n",
      "Accuracy: 0.7982034412955465\n",
      "Confusion matrix:\n",
      " [[4640  374]\n",
      " [1221 1669]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.93      0.85      5014\n",
      "           1       0.82      0.58      0.68      2890\n",
      "\n",
      "    accuracy                           0.80      7904\n",
      "   macro avg       0.80      0.75      0.77      7904\n",
      "weighted avg       0.80      0.80      0.79      7904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(\"Test set accuracy:\", accuracy)\n",
    "\n",
    "print(\"TEST\")\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_classes))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred_classes))\n",
    "print(\"Classification report:\\n\", classification_report(y_test, y_pred_classes))\n",
    "\n",
    "print(\"TRAIN\")\n",
    "y_pred = model.predict(X_train)\n",
    "y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_pred_classes))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_train, y_pred_classes))\n",
    "print(\"Classification report:\\n\", classification_report(y_train, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make predictions on the test set\n",
    "# y_pred = model.predict(X_test)\n",
    "# y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "#\n",
    "# # Print the predicted and actual labels\n",
    "# print(\"Predicted labels:\", y_pred_classes.flatten())\n",
    "# print(\"Actual labels:\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test with new data\n",
    "#\n",
    "# new_data = [\n",
    "#   ([\"dominican pop\", \"merengue\", \"merengue tipico\", \"tropical\"],\n",
    "#    [\"blues rock\", \"country rock\", \"lounge\"])\n",
    "# ]\n",
    "#\n",
    "# labels = [\n",
    "#\n",
    "# ]\n",
    "#\n",
    "# new_df = pd.DataFrame(new_data, columns=[\"genres\", \"favourite_genres\"])\n",
    "#\n",
    "# # Combine genres and favourite_genres\n",
    "# all_new_genres = list(new_df['genres'] + new_df['favourite_genres'])\n",
    "#\n",
    "# # One-hot encode the genres using the previously fit MultiLabelBinarizer (mlb)\n",
    "# encoded_new_genres = mlb.transform(all_new_genres)\n",
    "#\n",
    "# # Split encoded_new_genres into genres and favourite_genres\n",
    "# encoded_new_genres1 = encoded_new_genres[:, :len(new_df['genres'][0])]\n",
    "# encoded_new_genres2 = encoded_new_genres[:, len(new_df['genres'][0]):]\n",
    "#\n",
    "# # Concatenate the one-hot encoded columns\n",
    "# X_new = np.concatenate([encoded_new_genres1, encoded_new_genres2], axis=1)\n",
    "#\n",
    "# y_new_pred = model.predict(X_new)\n",
    "# y_new_pred_classes = (y_new_pred > 0.5).astype(int)\n",
    "#\n",
    "# # Print the predicted labels\n",
    "# print(\"Predicted labels:\", y_new_pred_classes.flatten())\n",
    "# print(\"Actual labels:\", labels)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (IUM)",
   "language": "python",
   "name": "ium"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
