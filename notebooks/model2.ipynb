{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T16:45:29.254452Z",
     "start_time": "2023-04-27T16:45:29.088384Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Input\n",
    "import keras_tuner\n",
    "\n",
    "from tensorboard.plugins.hparams import api as hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T16:45:29.471102Z",
     "start_time": "2023-04-27T16:45:29.092628Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_VERSION = \"v2\"\n",
    "\n",
    "merged_data_path = f'../data/{DATA_VERSION}/merged_data.jsonl'\n",
    "data = pd.read_json(merged_data_path, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-MEANS\n",
    "\n",
    "# Prepare the list of unique genres\n",
    "unique_genres = list(set([genre for genres in data['genres'] for genre in genres]) | set(\n",
    "    [genre for genres in data['favourite_genres'] for genre in genres]))\n",
    "\n",
    "# Convert the genres to a matrix of TF-IDF features\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorized = vectorizer.fit_transform(unique_genres)\n",
    "\n",
    "# Apply K-means clustering\n",
    "num_clusters = 100  # Adjust this value according to your needs\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init='auto')\n",
    "kmeans.fit(vectorized)\n",
    "labels = kmeans.labels_\n",
    "\n",
    "# Group the genres based on the cluster labels\n",
    "clustered_genres = {}\n",
    "for i, label in enumerate(labels):\n",
    "    if label not in clustered_genres:\n",
    "        clustered_genres[label] = []\n",
    "    clustered_genres[label].append(unique_genres[i])\n",
    "\n",
    "# Map genres to their cluster label\n",
    "genre_to_cluster = {genre: label for label, genres in clustered_genres.items() for genre in genres}\n",
    "\n",
    "\n",
    "# Define the function for mapping genres to simpler forms\n",
    "def map_genre(genre):\n",
    "    cluster_label = genre_to_cluster[genre]\n",
    "    representative_genre = clustered_genres[cluster_label][\n",
    "        0]  # Use the first genre in the cluster as the representative\n",
    "    return representative_genre\n",
    "\n",
    "\n",
    "# Save the genre_to_cluster and clustered_genres dictionaries to use for new data prediction\n",
    "with open('../microservice/models/model2_genre_to_cluster.pickle', 'wb') as f:\n",
    "    pickle.dump(genre_to_cluster, f)\n",
    "\n",
    "with open('../microservice/models/model2_clustered_genres.pickle', 'wb') as f:\n",
    "    pickle.dump(clustered_genres, f)\n",
    "\n",
    "# Apply the mapping function to both 'genres' and 'favourite_genres' columns\n",
    "data['genres'] = data['genres'].apply(lambda x: [map_genre(genre) for genre in x])\n",
    "data['favourite_genres'] = data['favourite_genres'].apply(lambda x: [map_genre(genre) for genre in x])\n",
    "\n",
    "# Delete not unique genres\n",
    "data['genres'] = data['genres'].apply(lambda x: list(set(x)))\n",
    "data['favourite_genres'] = data['favourite_genres'].apply(lambda x: list(set(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('vallenato moderno', 5622),\n",
       " ('math rock', 4695),\n",
       " ('classic greek rock', 3014),\n",
       " ('pop emo', 2771),\n",
       " ('flemish folk', 1619),\n",
       " ('country', 984),\n",
       " ('jump blues', 913),\n",
       " ('pop rap', 658),\n",
       " ('belly dance', 622),\n",
       " ('dark minimal techno', 580),\n",
       " ('swedish hip hop', 580),\n",
       " ('classic bulgarian pop', 546),\n",
       " ('polish alternative', 546),\n",
       " ('singer-songwriter', 544),\n",
       " ('new wave of thrash metal', 544),\n",
       " ('glam metal', 523),\n",
       " ('indonesian metal', 518),\n",
       " ('indie soul', 386),\n",
       " ('trap latino', 381),\n",
       " ('latin worship', 374),\n",
       " ('progressive groove metal', 364),\n",
       " ('hungarian punk', 341),\n",
       " ('brit funk', 319),\n",
       " ('canadian indie', 295),\n",
       " ('neo-crust', 221),\n",
       " ('jazz trumpet', 215),\n",
       " ('soulful house', 215),\n",
       " ('disco house', 180),\n",
       " ('contemporary vocal jazz', 175),\n",
       " ('girl group', 173),\n",
       " ('rap underground espanol', 137),\n",
       " ('drill francais', 123),\n",
       " ('mexican rock-and-roll', 111),\n",
       " ('beat italiano', 108),\n",
       " ('australian indigenous', 107),\n",
       " ('brazilian edm', 104),\n",
       " ('indian fusion', 102),\n",
       " ('mandopop', 100),\n",
       " ('german reggae', 94),\n",
       " ('deep power-pop punk', 85),\n",
       " ('nova musica pernambucana', 82),\n",
       " ('irish rebel song', 80),\n",
       " ('early synthpop', 77),\n",
       " ('french folk', 69),\n",
       " ('argentine reggae', 68),\n",
       " ('swamp rock', 62),\n",
       " ('marathi traditional', 62),\n",
       " ('musica popular paraense', 61),\n",
       " ('danish post-punk', 58),\n",
       " ('russian underground rap', 57),\n",
       " ('italian bass', 57),\n",
       " (\"canadian children's music\", 53),\n",
       " ('samba-rock', 53),\n",
       " ('acid house', 52),\n",
       " ('italian trance', 51),\n",
       " ('slack-key guitar', 48),\n",
       " ('vintage italian soundtrack', 47),\n",
       " ('cumbia sonidera', 46),\n",
       " ('spanish modern rock', 45),\n",
       " ('mainland chinese pop', 45),\n",
       " ('iskelma', 44),\n",
       " ('icelandic indie', 42),\n",
       " ('turkish psych', 41),\n",
       " ('uk experimental electronic', 38),\n",
       " ('folklore ecuatoriano', 37),\n",
       " ('german power metal', 36),\n",
       " ('salsa choke', 36),\n",
       " ('tagalog worship', 36),\n",
       " ('dutch rock', 35),\n",
       " ('hollywood', 35),\n",
       " ('classic japanese jazz', 34),\n",
       " ('calming instrumental', 32),\n",
       " ('harlem renaissance', 30),\n",
       " ('pagode', 30),\n",
       " ('classical baritone', 26),\n",
       " ('minneapolis sound', 24),\n",
       " ('happy hardcore', 22),\n",
       " ('norteno', 22),\n",
       " ('bluegrass', 20),\n",
       " ('tango', 18),\n",
       " ('melodic death metal', 17),\n",
       " ('j-idol', 15),\n",
       " ('magyar mulatos', 14),\n",
       " ('cuban rumba', 14),\n",
       " ('south african pop', 14),\n",
       " ('arab folk', 13),\n",
       " ('cumbia villera', 12),\n",
       " ('nordnorsk musikk', 10),\n",
       " ('trova mexicana', 9),\n",
       " ('chanson quebecois', 7),\n",
       " ('violin', 7),\n",
       " ('freak folk', 6),\n",
       " ('mariachi cristiano', 6),\n",
       " ('black thrash', 5),\n",
       " ('swiss folk', 4),\n",
       " ('palm desert scene', 4),\n",
       " ('jazz cubano', 3),\n",
       " ('british comedy', 2),\n",
       " ('hardstyle', 2),\n",
       " ('new mexico music', 1)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count unique genres\n",
    "unique_genres = set()\n",
    "for genres in data['genres']:\n",
    "    unique_genres.update(genres)\n",
    "for genres in data['favourite_genres']:\n",
    "    unique_genres.update(genres)\n",
    "print(len(unique_genres))\n",
    "\n",
    "# how many tracks are per genre\n",
    "genre_count = {}\n",
    "for genres in data['genres']:\n",
    "    for genre in genres:\n",
    "        if genre not in genre_count:\n",
    "            genre_count[genre] = 0\n",
    "        genre_count[genre] += 1\n",
    "\n",
    "genre_count = sorted(genre_count.items(), key=lambda x: x[1], reverse=True)\n",
    "genre_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T16:45:29.545713Z",
     "start_time": "2023-04-27T16:45:29.475341Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipped_data (3621, 3)\n",
      "not_skipped_data (6260, 3)\n"
     ]
    }
   ],
   "source": [
    "# balance set\n",
    "skipped_data = data[data[\"skipped\"] == 1]\n",
    "not_skipped_data = data[data[\"skipped\"] == 0]\n",
    "\n",
    "# Split the dataset into subsets based on class labels\n",
    "print(\"skipped_data\", skipped_data.shape)\n",
    "print(\"not_skipped_data\", not_skipped_data.shape)\n",
    "\n",
    "# Calculate the minimum number of samples among all classes\n",
    "min_samples = min(len(skipped_data), len(not_skipped_data))\n",
    "\n",
    "# Randomly select samples from each class subset to match the minimum number of samples\n",
    "skipped_data_balanced = skipped_data.sample(n=min_samples, random_state=42)\n",
    "not_skipped_data_balanced = not_skipped_data.sample(n=min_samples, random_state=42)\n",
    "\n",
    "# Merge the balanced subsets to create the final balanced dataset\n",
    "balanced_data = pd.concat([skipped_data_balanced, not_skipped_data_balanced], axis=0)\n",
    "\n",
    "# Shuffle the balanced dataset\n",
    "balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T16:36:02.187991Z",
     "start_time": "2023-04-27T16:36:02.115285Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Combine genres and favourite_genres\n",
    "mlb = MultiLabelBinarizer()\n",
    "\n",
    "data['combined_genres'] = data.apply(lambda x: x['genres'] + x['favourite_genres'], axis=1)\n",
    "mlb.fit(data['combined_genres'])\n",
    "\n",
    "encoded_favourite_genres = mlb.transform(balanced_data['favourite_genres'])\n",
    "encoded_genres = mlb.transform(balanced_data['genres'])\n",
    "\n",
    "# save mlb to file\n",
    "with open('../microservice/models/model2_mlb.pickle', 'wb') as f:\n",
    "    pickle.dump(mlb, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T16:36:02.188192Z",
     "start_time": "2023-04-27T16:36:02.130018Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train not skipped 2921\n",
      "Y_train skipped 2872\n",
      "Y_train skipped % 0.4957707578111514\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate([encoded_genres, encoded_favourite_genres], axis=1)\n",
    "\n",
    "# Extract the labels\n",
    "y = balanced_data['skipped'].astype(int).values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
    "\n",
    "# count skipped and not skipped songs in X_train\n",
    "print(\"Y_train not skipped\", np.count_nonzero(y_train == 0))\n",
    "print(\"Y_train skipped\", np.count_nonzero(y_train == 1))\n",
    "print(\"Y_train skipped %\", np.count_nonzero(y_train == 1) / len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mode = \"train\"\n",
    "mode = \"tune\"\n",
    "\n",
    "# NOTATKI Z TRAINU\n",
    "# 1 layer - ???\n",
    "# 2 layer - 100,100 neuronow 0.001 learning rate (20 epok, 0.655 acc) dropout (0.5)\n",
    "# 2 layer - 111,41  neuronow 0.003 learning rate (20 epok, 0.670 acc) dropout (0.5)\n",
    "\n",
    "# NOTATKI Z TUNINGU\n",
    "# 1 layer - 31 neuronow, 0.0067 learning rate (x epok, y ac) dropout (0.5)\n",
    "# 2 layer - 100,100 neuronow, 0.001 learning rate (10 epok, 0.641 acc) bez dropoutu\n",
    "#         - 111,41 neuronow, 0.003 learning rate bez dropoutu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    if mode == \"train\":\n",
    "        model = Sequential()\n",
    "        model.add(Input(shape=(X_train.shape[1])))\n",
    "        model.add(Dense(units=110, activation=\"relu\"))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(units=40, activation=\"relu\"))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=0.003),\n",
    "            loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    else:\n",
    "        model = Sequential()\n",
    "        model.add(Input(shape=(X_train.shape[1])))\n",
    "\n",
    "        for i in range(hp.Int(\"num_layers\", min_value=1, max_value=3)):\n",
    "            model.add(Dense(units=hp.Int(f\"units_{i}\", min_value=1, max_value=200, step=5), activation=\"relu\"))\n",
    "            if hp.Boolean(\"dropout\"):\n",
    "                model.add(Dropout(0.5))\n",
    "\n",
    "        model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "        model.compile(optimizer=Adam(learning_rate=hp.Float(\"learning_rate\", min_value=0.001, max_value=0.01, sampling=\"log\")),loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-27T16:36:16.010901Z",
     "start_time": "2023-04-27T16:36:02.139531Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 1 Complete [00h 01m 46s]\n",
      "val_accuracy: 0.6507936418056488\n",
      "\n",
      "Best val_accuracy So Far: 0.6507936418056488\n",
      "Total elapsed time: 00h 01m 46s\n",
      "\n",
      "Search: Running Trial #2\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "3                 |2                 |num_layers\n",
      "111               |136               |units_0\n",
      "False             |True              |dropout\n",
      "0.0028229         |0.0013438         |learning_rate\n",
      "36                |1                 |units_1\n",
      "\n",
      "Epoch 1/50\n",
      "182/182 [==============================] - 9s 46ms/step - loss: 0.6720 - accuracy: 0.5949 - val_loss: 0.6553 - val_accuracy: 0.6349\n",
      "Epoch 2/50\n",
      "182/182 [==============================] - 7s 40ms/step - loss: 0.6388 - accuracy: 0.6484 - val_loss: 0.6447 - val_accuracy: 0.6494\n",
      "Epoch 3/50\n",
      "182/182 [==============================] - 7s 38ms/step - loss: 0.6207 - accuracy: 0.6699 - val_loss: 0.6412 - val_accuracy: 0.6542\n",
      "Epoch 4/50\n",
      "182/182 [==============================] - 8s 42ms/step - loss: 0.6083 - accuracy: 0.6794 - val_loss: 0.6605 - val_accuracy: 0.6460\n",
      "Epoch 5/50\n",
      "182/182 [==============================] - 8s 43ms/step - loss: 0.5975 - accuracy: 0.6820 - val_loss: 0.6422 - val_accuracy: 0.6584\n",
      "Epoch 6/50\n",
      "182/182 [==============================] - 10s 54ms/step - loss: 0.5822 - accuracy: 0.7038 - val_loss: 0.6401 - val_accuracy: 0.6660\n",
      "Epoch 7/50\n",
      "182/182 [==============================] - 7s 39ms/step - loss: 0.5741 - accuracy: 0.7046 - val_loss: 0.6520 - val_accuracy: 0.6570\n",
      "Epoch 8/50\n",
      "182/182 [==============================] - 7s 40ms/step - loss: 0.5556 - accuracy: 0.7191 - val_loss: 0.6660 - val_accuracy: 0.6501\n",
      "Epoch 9/50\n",
      "182/182 [==============================] - 10s 53ms/step - loss: 0.5509 - accuracy: 0.7221 - val_loss: 0.6756 - val_accuracy: 0.6529\n",
      "Epoch 10/50\n",
      "182/182 [==============================] - 8s 41ms/step - loss: 0.5364 - accuracy: 0.7335 - val_loss: 0.7099 - val_accuracy: 0.6605\n",
      "Epoch 11/50\n",
      "182/182 [==============================] - 9s 48ms/step - loss: 0.5255 - accuracy: 0.7430 - val_loss: 0.6940 - val_accuracy: 0.6473\n",
      "Epoch 1/50\n",
      "182/182 [==============================] - 12s 64ms/step - loss: 0.6783 - accuracy: 0.5738 - val_loss: 0.6671 - val_accuracy: 0.6108\n",
      "Epoch 2/50\n",
      "182/182 [==============================] - 10s 55ms/step - loss: 0.6529 - accuracy: 0.6183 - val_loss: 0.6748 - val_accuracy: 0.6225\n",
      "Epoch 3/50\n",
      "182/182 [==============================] - 10s 57ms/step - loss: 0.6279 - accuracy: 0.6615 - val_loss: 0.6388 - val_accuracy: 0.6680\n",
      "Epoch 4/50\n",
      "182/182 [==============================] - 10s 56ms/step - loss: 0.6136 - accuracy: 0.6701 - val_loss: 0.6365 - val_accuracy: 0.6667\n",
      "Epoch 5/50\n",
      "182/182 [==============================] - 11s 63ms/step - loss: 0.6006 - accuracy: 0.6832 - val_loss: 0.6364 - val_accuracy: 0.6653\n",
      "Epoch 6/50\n",
      " 50/182 [=======>......................] - ETA: 13s - loss: 0.5827 - accuracy: 0.6975"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[116], line 38\u001b[0m\n\u001b[1;32m     34\u001b[0m tensorboard_callback \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mTensorBoard(log_dir\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlogs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m tuner\u001b[39m.\u001b[39msearch_space_summary()\n\u001b[0;32m---> 38\u001b[0m tuner\u001b[39m.\u001b[39;49msearch(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_test, y_test), callbacks\u001b[39m=\u001b[39;49m[stop_early, tensorboard_callback])\n\u001b[1;32m     40\u001b[0m tuner\u001b[39m.\u001b[39mresults_summary()\n",
      "File \u001b[0;32m~/anaconda3/envs/IUM/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py:183\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 183\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    184\u001b[0m \u001b[39m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[39mif\u001b[39;00m results \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/IUM/lib/python3.10/site-packages/keras_tuner/engine/tuner.py:295\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    294\u001b[0m     copied_kwargs[\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m callbacks\n\u001b[0;32m--> 295\u001b[0m     obj_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_and_fit_model(trial, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcopied_kwargs)\n\u001b[1;32m    297\u001b[0m     histories\u001b[39m.\u001b[39mappend(obj_value)\n\u001b[1;32m    298\u001b[0m \u001b[39mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m~/anaconda3/envs/IUM/lib/python3.10/site-packages/keras_tuner/engine/tuner.py:222\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m hp \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39mhyperparameters\n\u001b[1;32m    221\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 222\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhypermodel\u001b[39m.\u001b[39;49mfit(hp, model, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    223\u001b[0m tuner_utils\u001b[39m.\u001b[39mvalidate_trial_results(\n\u001b[1;32m    224\u001b[0m     results, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective, \u001b[39m\"\u001b[39m\u001b[39mHyperModel.fit()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    225\u001b[0m )\n\u001b[1;32m    226\u001b[0m \u001b[39mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/anaconda3/envs/IUM/lib/python3.10/site-packages/keras_tuner/engine/hypermodel.py:140\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    117\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \n\u001b[1;32m    119\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39;49mfit(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/IUM/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/IUM/lib/python3.10/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/IUM/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/IUM/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/IUM/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/IUM/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/IUM/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/IUM/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/envs/IUM/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if mode == \"train\":\n",
    "    model = build_model(None)\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=20,\n",
    "        batch_size=32,\n",
    "        verbose=2\n",
    "    )\n",
    "else:\n",
    "    # tuner = keras_tuner.RandomSearch(\n",
    "    #     hypermodel=build_model,\n",
    "    #     objective=\"val_accuracy\",\n",
    "    #     max_trials=50,\n",
    "    #     executions_per_trial=1,\n",
    "    #     overwrite=True,\n",
    "    #     directory=\"tuner\",\n",
    "    #     project_name=\"IUM\",\n",
    "    # )\n",
    "\n",
    "    tuner = keras_tuner.Hyperband(\n",
    "        hypermodel=build_model,\n",
    "        objective=\"val_accuracy\",\n",
    "        max_epochs=20,\n",
    "        factor=3,\n",
    "        executions_per_trial=1,\n",
    "        overwrite=True,\n",
    "        directory=\"tuner\",\n",
    "        project_name=\"IUM\",\n",
    "    )\n",
    "\n",
    "    stop_early = keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=\"logs\")\n",
    "\n",
    "    tuner.search_space_summary()\n",
    "\n",
    "    tuner.search(X_train, y_train, epochs=50, validation_data=(X_test, y_test), callbacks=[stop_early, tensorboard_callback])\n",
    "\n",
    "    tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST\n",
      "46/46 [==============================] - 0s 3ms/step\n",
      "Accuracy: 0.6701173222912353\n",
      "Confusion matrix:\n",
      " [[439 291]\n",
      " [187 532]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.60      0.65       730\n",
      "           1       0.65      0.74      0.69       719\n",
      "\n",
      "    accuracy                           0.67      1449\n",
      "   macro avg       0.67      0.67      0.67      1449\n",
      "weighted avg       0.67      0.67      0.67      1449\n",
      "\n",
      "TRAIN\n",
      "182/182 [==============================] - 0s 2ms/step\n",
      "Accuracy: 0.7431382703262558\n",
      "Confusion matrix:\n",
      " [[1904  987]\n",
      " [ 501 2401]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.66      0.72      2891\n",
      "           1       0.71      0.83      0.76      2902\n",
      "\n",
      "    accuracy                           0.74      5793\n",
      "   macro avg       0.75      0.74      0.74      5793\n",
      "weighted avg       0.75      0.74      0.74      5793\n",
      "\n",
      "ALL\n",
      "227/227 [==============================] - 0s 2ms/step\n",
      "Accuracy: 0.7285280309306821\n",
      "Confusion matrix:\n",
      " [[2343 1278]\n",
      " [ 688 2933]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.65      0.70      3621\n",
      "           1       0.70      0.81      0.75      3621\n",
      "\n",
      "    accuracy                           0.73      7242\n",
      "   macro avg       0.73      0.73      0.73      7242\n",
      "weighted avg       0.73      0.73      0.73      7242\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if mode == \"train\":\n",
    "    # save model to file\n",
    "    model.save('../models/model2.h5')\n",
    "\n",
    "    print(\"TEST\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred_classes))\n",
    "    print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred_classes))\n",
    "    print(\"Classification report:\\n\", classification_report(y_test, y_pred_classes))\n",
    "\n",
    "    print(\"TRAIN\")\n",
    "    y_pred = model.predict(X_train)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "    print(\"Accuracy:\", accuracy_score(y_train, y_pred_classes))\n",
    "    print(\"Confusion matrix:\\n\", confusion_matrix(y_train, y_pred_classes))\n",
    "    print(\"Classification report:\\n\", classification_report(y_train, y_pred_classes))\n",
    "\n",
    "    print(\"ALL\")\n",
    "    y_pred = model.predict(X)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "    print(\"Accuracy:\", accuracy_score(y, y_pred_classes))\n",
    "    print(\"Confusion matrix:\\n\", confusion_matrix(y, y_pred_classes))\n",
    "    print(\"Classification report:\\n\", classification_report(y, y_pred_classes))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (IUM)",
   "language": "python",
   "name": "ium"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
