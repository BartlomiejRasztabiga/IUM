{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "# import keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "   popularity  duration_ms  danceability  energy  speechiness  acousticness   \n0          34       247707         0.491   0.606       0.0377       0.00327  \\\n1          34       247707         0.491   0.606       0.0377       0.00327   \n2          34       247707         0.491   0.606       0.0377       0.00327   \n3          35       140067         0.449   0.749       0.0775       0.01000   \n4          35       140067         0.449   0.749       0.0775       0.01000   \n\n   instrumentalness  liveness  valence    tempo   \n0          0.000008     0.341    0.669  123.025  \\\n1          0.000008     0.341    0.669  123.025   \n2          0.000008     0.341    0.669  123.025   \n3          0.000000     0.391    0.448  106.861   \n4          0.000000     0.391    0.448  106.861   \n\n                                    favourite_genres   \n0                   [permanent wave, mandopop, funk]  \\\n1                    [filmi, regional mexican, folk]   \n2  [psychedelic rock, country rock, rock en espanol]   \n3  [psychedelic rock, country rock, rock en espanol]   \n4  [psychedelic rock, country rock, rock en espanol]   \n\n                                              genres  skipped  \n0  [album rock, art rock, classic rock, folk rock...    False  \n1  [album rock, art rock, classic rock, folk rock...    False  \n2  [album rock, art rock, classic rock, folk rock...    False  \n3  [album rock, art rock, classic rock, folk rock...    False  \n4  [album rock, art rock, classic rock, folk rock...    False  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>popularity</th>\n      <th>duration_ms</th>\n      <th>danceability</th>\n      <th>energy</th>\n      <th>speechiness</th>\n      <th>acousticness</th>\n      <th>instrumentalness</th>\n      <th>liveness</th>\n      <th>valence</th>\n      <th>tempo</th>\n      <th>favourite_genres</th>\n      <th>genres</th>\n      <th>skipped</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>34</td>\n      <td>247707</td>\n      <td>0.491</td>\n      <td>0.606</td>\n      <td>0.0377</td>\n      <td>0.00327</td>\n      <td>0.000008</td>\n      <td>0.341</td>\n      <td>0.669</td>\n      <td>123.025</td>\n      <td>[permanent wave, mandopop, funk]</td>\n      <td>[album rock, art rock, classic rock, folk rock...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>34</td>\n      <td>247707</td>\n      <td>0.491</td>\n      <td>0.606</td>\n      <td>0.0377</td>\n      <td>0.00327</td>\n      <td>0.000008</td>\n      <td>0.341</td>\n      <td>0.669</td>\n      <td>123.025</td>\n      <td>[filmi, regional mexican, folk]</td>\n      <td>[album rock, art rock, classic rock, folk rock...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>34</td>\n      <td>247707</td>\n      <td>0.491</td>\n      <td>0.606</td>\n      <td>0.0377</td>\n      <td>0.00327</td>\n      <td>0.000008</td>\n      <td>0.341</td>\n      <td>0.669</td>\n      <td>123.025</td>\n      <td>[psychedelic rock, country rock, rock en espanol]</td>\n      <td>[album rock, art rock, classic rock, folk rock...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>35</td>\n      <td>140067</td>\n      <td>0.449</td>\n      <td>0.749</td>\n      <td>0.0775</td>\n      <td>0.01000</td>\n      <td>0.000000</td>\n      <td>0.391</td>\n      <td>0.448</td>\n      <td>106.861</td>\n      <td>[psychedelic rock, country rock, rock en espanol]</td>\n      <td>[album rock, art rock, classic rock, folk rock...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>35</td>\n      <td>140067</td>\n      <td>0.449</td>\n      <td>0.749</td>\n      <td>0.0775</td>\n      <td>0.01000</td>\n      <td>0.000000</td>\n      <td>0.391</td>\n      <td>0.448</td>\n      <td>106.861</td>\n      <td>[psychedelic rock, country rock, rock en espanol]</td>\n      <td>[album rock, art rock, classic rock, folk rock...</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data_path = '../data/merged_data.jsonl'\n",
    "data = pd.read_json(merged_data_path, lines=True)\n",
    "\n",
    "data = data.drop(\n",
    "    columns=[\"release_date\", \"key\", \"loudness\",\n",
    "             \"explicit\", ])\n",
    "\n",
    "data.head(5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "# Combine genres and favourite_genres\n",
    "all_genres = list(data['favourite_genres'] + data['genres'])\n",
    "\n",
    "# TODO usunac nieznane gatunki z listy genres?\n",
    "\n",
    "# One-hot encode the genres\n",
    "mlb = MultiLabelBinarizer()\n",
    "encoded_all_genres = mlb.fit_transform(all_genres)\n",
    "\n",
    "# Split encoded_genres into genres and favourite_genres\n",
    "encoded_favourite_genres = encoded_all_genres[:, :len(data['favourite_genres'][0])]\n",
    "encoded_genres = encoded_all_genres[:, len(data['favourite_genres'][0]):]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "# Concatenate the one-hot encoded columns\n",
    "X = np.concatenate([encoded_favourite_genres, encoded_genres], axis=1)\n",
    "# Extract the labels\n",
    "y = data['skipped'].astype(int).values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "  model = Sequential()\n",
    "  model.add(Dense(6000, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(3000, activation='relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(1000, activation='relu'))\n",
    "  model.add(Dropout(0.5))\n",
    "  model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "  # model.compile(\n",
    "  #     optimizer=keras.optimizers.Adam(hp.Choice('learning_date', values=[0.5, 0.1, 0.01])),\n",
    "  #     loss='binary_crossentropy', metrics=['accuracy'])\n",
    "  model.compile(\n",
    "      optimizer='adam',\n",
    "      loss='binary_crossentropy', metrics=['accuracy'])\n",
    "  return model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2 Pro\n",
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-04 21:18:05.910616: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198/198 - 5s - loss: 0.6398 - accuracy: 0.6453 - val_loss: 0.6102 - val_accuracy: 0.6755 - 5s/epoch - 23ms/step\n",
      "Epoch 2/25\n",
      "198/198 - 4s - loss: 0.5765 - accuracy: 0.6937 - val_loss: 0.5935 - val_accuracy: 0.6768 - 4s/epoch - 19ms/step\n",
      "Epoch 3/25\n",
      "198/198 - 4s - loss: 0.5349 - accuracy: 0.7221 - val_loss: 0.6284 - val_accuracy: 0.6641 - 4s/epoch - 20ms/step\n",
      "Epoch 4/25\n",
      "198/198 - 4s - loss: 0.4917 - accuracy: 0.7457 - val_loss: 0.6629 - val_accuracy: 0.6730 - 4s/epoch - 18ms/step\n",
      "Epoch 5/25\n",
      "198/198 - 4s - loss: 0.4468 - accuracy: 0.7759 - val_loss: 0.6572 - val_accuracy: 0.6679 - 4s/epoch - 18ms/step\n",
      "Epoch 6/25\n",
      "198/198 - 4s - loss: 0.4104 - accuracy: 0.7955 - val_loss: 0.7284 - val_accuracy: 0.6528 - 4s/epoch - 18ms/step\n",
      "Epoch 7/25\n",
      "198/198 - 4s - loss: 0.3872 - accuracy: 0.8156 - val_loss: 0.8476 - val_accuracy: 0.6534 - 4s/epoch - 18ms/step\n",
      "Epoch 8/25\n",
      "198/198 - 4s - loss: 0.3546 - accuracy: 0.8246 - val_loss: 0.8365 - val_accuracy: 0.6483 - 4s/epoch - 18ms/step\n",
      "Epoch 9/25\n",
      "198/198 - 3s - loss: 0.3319 - accuracy: 0.8377 - val_loss: 0.8249 - val_accuracy: 0.6717 - 3s/epoch - 18ms/step\n",
      "Epoch 10/25\n",
      "198/198 - 3s - loss: 0.3206 - accuracy: 0.8444 - val_loss: 0.8778 - val_accuracy: 0.6610 - 3s/epoch - 18ms/step\n",
      "Epoch 11/25\n",
      "198/198 - 4s - loss: 0.3094 - accuracy: 0.8442 - val_loss: 0.8910 - val_accuracy: 0.6388 - 4s/epoch - 18ms/step\n",
      "Epoch 12/25\n",
      "198/198 - 4s - loss: 0.2903 - accuracy: 0.8550 - val_loss: 0.9671 - val_accuracy: 0.6414 - 4s/epoch - 18ms/step\n",
      "Epoch 13/25\n",
      "198/198 - 3s - loss: 0.2827 - accuracy: 0.8624 - val_loss: 0.9833 - val_accuracy: 0.6597 - 3s/epoch - 18ms/step\n",
      "Epoch 14/25\n",
      "198/198 - 4s - loss: 0.2686 - accuracy: 0.8664 - val_loss: 0.9846 - val_accuracy: 0.6509 - 4s/epoch - 18ms/step\n",
      "Epoch 15/25\n",
      "198/198 - 4s - loss: 0.2610 - accuracy: 0.8653 - val_loss: 1.0774 - val_accuracy: 0.6515 - 4s/epoch - 18ms/step\n",
      "Epoch 16/25\n",
      "198/198 - 4s - loss: 0.2525 - accuracy: 0.8711 - val_loss: 1.0366 - val_accuracy: 0.6534 - 4s/epoch - 19ms/step\n",
      "Epoch 17/25\n",
      "198/198 - 4s - loss: 0.2520 - accuracy: 0.8719 - val_loss: 1.2717 - val_accuracy: 0.6711 - 4s/epoch - 18ms/step\n",
      "Epoch 18/25\n",
      "198/198 - 3s - loss: 0.2390 - accuracy: 0.8771 - val_loss: 1.0717 - val_accuracy: 0.6591 - 3s/epoch - 18ms/step\n",
      "Epoch 19/25\n",
      "198/198 - 3s - loss: 0.2301 - accuracy: 0.8836 - val_loss: 1.3914 - val_accuracy: 0.6515 - 3s/epoch - 17ms/step\n",
      "Epoch 20/25\n",
      "198/198 - 4s - loss: 0.2311 - accuracy: 0.8803 - val_loss: 1.3923 - val_accuracy: 0.6597 - 4s/epoch - 18ms/step\n",
      "Epoch 21/25\n",
      "198/198 - 4s - loss: 0.2251 - accuracy: 0.8828 - val_loss: 1.1855 - val_accuracy: 0.6603 - 4s/epoch - 18ms/step\n",
      "Epoch 22/25\n",
      "198/198 - 3s - loss: 0.2185 - accuracy: 0.8885 - val_loss: 1.4566 - val_accuracy: 0.6407 - 3s/epoch - 18ms/step\n",
      "Epoch 23/25\n",
      "198/198 - 3s - loss: 0.2156 - accuracy: 0.8885 - val_loss: 1.2507 - val_accuracy: 0.6578 - 3s/epoch - 18ms/step\n",
      "Epoch 24/25\n",
      "198/198 - 4s - loss: 0.2054 - accuracy: 0.8950 - val_loss: 1.3620 - val_accuracy: 0.6382 - 4s/epoch - 18ms/step\n",
      "Epoch 25/25\n",
      "198/198 - 4s - loss: 0.2105 - accuracy: 0.8947 - val_loss: 1.6372 - val_accuracy: 0.6553 - 4s/epoch - 18ms/step\n"
     ]
    }
   ],
   "source": [
    "epochs = 25\n",
    "batch_size = 32\n",
    "\n",
    "model = build_model(None)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# tuner = keras_tuner.tuners.Hyperband(\n",
    "#     build_model,\n",
    "#     objective='val_accuracy',\n",
    "#     max_epochs=50,\n",
    "#     max_trials=10,\n",
    "#     executions_per_trial=2,\n",
    "#     directory='my_dir')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "# tuner.search(\n",
    "#     (X_train, y_train),\n",
    "#     validation_data=(X_test, y_test),\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 - 0s - loss: 1.8383 - accuracy: 0.6525 - 287ms/epoch - 5ms/step\n",
      "Test set accuracy: 0.6525037884712219\n",
      "TEST\n",
      "62/62 [==============================] - 0s 3ms/step\n",
      "Accuracy: 0.6525037936267072\n",
      "Confusion matrix:\n",
      " [[931 330]\n",
      " [357 359]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.74      0.73      1261\n",
      "           1       0.52      0.50      0.51       716\n",
      "\n",
      "    accuracy                           0.65      1977\n",
      "   macro avg       0.62      0.62      0.62      1977\n",
      "weighted avg       0.65      0.65      0.65      1977\n",
      "\n",
      "TRAIN\n",
      "247/247 [==============================] - 1s 3ms/step\n",
      "Accuracy: 0.8572874493927125\n",
      "Confusion matrix:\n",
      " [[4483  516]\n",
      " [ 612 2293]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89      4999\n",
      "           1       0.82      0.79      0.80      2905\n",
      "\n",
      "    accuracy                           0.86      7904\n",
      "   macro avg       0.85      0.84      0.85      7904\n",
      "weighted avg       0.86      0.86      0.86      7904\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(\"Test set accuracy:\", accuracy)\n",
    "\n",
    "print(\"TEST\")\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_classes))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test, y_pred_classes))\n",
    "print(\"Classification report:\\n\", classification_report(y_test, y_pred_classes))\n",
    "\n",
    "print(\"TRAIN\")\n",
    "y_pred = model.predict(X_train)\n",
    "y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "print(\"Accuracy:\", accuracy_score(y_train, y_pred_classes))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_train, y_pred_classes))\n",
    "print(\"Classification report:\\n\", classification_report(y_train, y_pred_classes))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "# # Make predictions on the test set\n",
    "# y_pred = model.predict(X_test)\n",
    "# y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "#\n",
    "# # Print the predicted and actual labels\n",
    "# print(\"Predicted labels:\", y_pred_classes.flatten())\n",
    "# print(\"Actual labels:\", y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "# # test with new data\n",
    "#\n",
    "# new_data = [\n",
    "#   ([\"dominican pop\", \"merengue\", \"merengue tipico\", \"tropical\"],\n",
    "#    [\"blues rock\", \"country rock\", \"lounge\"])\n",
    "# ]\n",
    "#\n",
    "# labels = [\n",
    "#\n",
    "# ]\n",
    "#\n",
    "# new_df = pd.DataFrame(new_data, columns=[\"genres\", \"favourite_genres\"])\n",
    "#\n",
    "# # Combine genres and favourite_genres\n",
    "# all_new_genres = list(new_df['genres'] + new_df['favourite_genres'])\n",
    "#\n",
    "# # One-hot encode the genres using the previously fit MultiLabelBinarizer (mlb)\n",
    "# encoded_new_genres = mlb.transform(all_new_genres)\n",
    "#\n",
    "# # Split encoded_new_genres into genres and favourite_genres\n",
    "# encoded_new_genres1 = encoded_new_genres[:, :len(new_df['genres'][0])]\n",
    "# encoded_new_genres2 = encoded_new_genres[:, len(new_df['genres'][0]):]\n",
    "#\n",
    "# # Concatenate the one-hot encoded columns\n",
    "# X_new = np.concatenate([encoded_new_genres1, encoded_new_genres2], axis=1)\n",
    "#\n",
    "# y_new_pred = model.predict(X_new)\n",
    "# y_new_pred_classes = (y_new_pred > 0.5).astype(int)\n",
    "#\n",
    "# # Print the predicted labels\n",
    "# print(\"Predicted labels:\", y_new_pred_classes.flatten())\n",
    "# print(\"Actual labels:\", labels)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "ium",
   "language": "python",
   "display_name": "Python 3.10 (IUM)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
