{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV\n",
    "from joblib import load, dump\n",
    "from skorch import NeuralNetClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Przygotowanie danych do uczenia\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "data": {
      "text/plain": "                                      favourite_genres  \\\n0                     [permanent wave, mandopop, funk]   \n1                      [filmi, regional mexican, folk]   \n2    [psychedelic rock, country rock, rock en espanol]   \n3    [psychedelic rock, country rock, rock en espanol]   \n4    [psychedelic rock, country rock, rock en espanol]   \n..                                                 ...   \n495  [hard rock, alternative metal, singer-songwriter]   \n496                   [permanent wave, mandopop, funk]   \n497                   [permanent wave, mandopop, funk]   \n498                    [filmi, regional mexican, folk]   \n499  [psychedelic rock, country rock, rock en espanol]   \n\n                                                genres  skipped  \n0    [album rock, art rock, classic rock, folk rock...    False  \n1    [album rock, art rock, classic rock, folk rock...    False  \n2    [album rock, art rock, classic rock, folk rock...    False  \n3    [album rock, art rock, classic rock, folk rock...    False  \n4    [album rock, art rock, classic rock, folk rock...    False  \n..                                                 ...      ...  \n495  [album rock, art rock, blues, blues rock, brit...    False  \n496  [album rock, art rock, classic rock, classic u...     True  \n497  [album rock, art rock, classic rock, classic u...     True  \n498  [album rock, art rock, classic rock, classic u...    False  \n499  [album rock, art rock, classic rock, classic u...     True  \n\n[500 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>favourite_genres</th>\n      <th>genres</th>\n      <th>skipped</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[permanent wave, mandopop, funk]</td>\n      <td>[album rock, art rock, classic rock, folk rock...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[filmi, regional mexican, folk]</td>\n      <td>[album rock, art rock, classic rock, folk rock...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[psychedelic rock, country rock, rock en espanol]</td>\n      <td>[album rock, art rock, classic rock, folk rock...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[psychedelic rock, country rock, rock en espanol]</td>\n      <td>[album rock, art rock, classic rock, folk rock...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[psychedelic rock, country rock, rock en espanol]</td>\n      <td>[album rock, art rock, classic rock, folk rock...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>495</th>\n      <td>[hard rock, alternative metal, singer-songwriter]</td>\n      <td>[album rock, art rock, blues, blues rock, brit...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>496</th>\n      <td>[permanent wave, mandopop, funk]</td>\n      <td>[album rock, art rock, classic rock, classic u...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>497</th>\n      <td>[permanent wave, mandopop, funk]</td>\n      <td>[album rock, art rock, classic rock, classic u...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>498</th>\n      <td>[filmi, regional mexican, folk]</td>\n      <td>[album rock, art rock, classic rock, classic u...</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>[psychedelic rock, country rock, rock en espanol]</td>\n      <td>[album rock, art rock, classic rock, classic u...</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>500 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data_path = '../data/merged_data.jsonl'\n",
    "data = pd.read_json(merged_data_path, lines=True)\n",
    "\n",
    "data = data.drop(columns=[\"user_id\", \"track_id\"])\n",
    "\n",
    "# TODO delete?\n",
    "data = data.drop(\n",
    "    columns=[\"release_date\", \"key\", \"loudness\", \"popularity\", \"duration_ms\", \"explicit\",\n",
    "             \"danceability\", \"energy\", \"speechiness\",\n",
    "             \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\", \"tempo\"])\n",
    "\n",
    "# data = data.drop(columns=[\"release_date\", \"explicit\", \"key\", \"loudness\", \"favourite_genres\", \"genres\"])\n",
    "\n",
    "\n",
    "# TODO map genres\n",
    "\n",
    "# def map_genres(genre):\n",
    "#   if \"rock\" in genre:\n",
    "#     return \"rock\"\n",
    "#   elif \"pop\" in genre:\n",
    "#     return \"pop\"\n",
    "#   elif \"dance\" in genre:\n",
    "#     return \"dance\"\n",
    "#   elif \"wave\" in genre:\n",
    "#     return \"wave\"\n",
    "#   elif \"metal\" in genre:\n",
    "#     return \"metal\"\n",
    "#   else:\n",
    "#     return genre\n",
    "#\n",
    "#\n",
    "# data[\"genres\"] = data[\"genres\"].apply(lambda genres: list(set(map(map_genres, genres))))\n",
    "# data[\"favourite_genres\"] = data[\"favourite_genres\"].apply(lambda genres: list(set(map(map_genres, genres))))\n",
    "\n",
    "data.head(500)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Zamiana wartości kategorycznych (genres) na liczbowe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "outputs": [
    {
     "data": {
      "text/plain": "   skipped  g_0  g_1  g_2  g_3  g_4  g_5  g_6  g_7  g_8  ...  fav_1756  \\\n0    False    0    0    0    0    0    0    0    0    0  ...         0   \n1    False    0    0    0    0    0    0    0    0    0  ...         0   \n2    False    0    0    0    0    0    0    0    0    0  ...         0   \n3    False    0    0    0    0    0    0    0    0    0  ...         0   \n4    False    0    0    0    0    0    0    0    0    0  ...         0   \n\n   fav_1757  fav_1758  fav_1759  fav_1760  fav_1761  fav_1762  fav_1763  \\\n0         0         0         0         0         0         0         0   \n1         0         0         0         0         0         0         0   \n2         0         0         0         0         0         0         0   \n3         0         0         0         0         0         0         0   \n4         0         0         0         0         0         0         0   \n\n   fav_1764  fav_1765  \n0         0         0  \n1         0         0  \n2         0         0  \n3         0         0  \n4         0         0  \n\n[5 rows x 3533 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>skipped</th>\n      <th>g_0</th>\n      <th>g_1</th>\n      <th>g_2</th>\n      <th>g_3</th>\n      <th>g_4</th>\n      <th>g_5</th>\n      <th>g_6</th>\n      <th>g_7</th>\n      <th>g_8</th>\n      <th>...</th>\n      <th>fav_1756</th>\n      <th>fav_1757</th>\n      <th>fav_1758</th>\n      <th>fav_1759</th>\n      <th>fav_1760</th>\n      <th>fav_1761</th>\n      <th>fav_1762</th>\n      <th>fav_1763</th>\n      <th>fav_1764</th>\n      <th>fav_1765</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>False</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 3533 columns</p>\n</div>"
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_genres = set.union(*data[\"genres\"].apply(set).tolist(),\n",
    "                          *data[\"favourite_genres\"].apply(set).tolist())\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(list(unique_genres))\n",
    "\n",
    "# convert the categorical values into numeric - favourite_genres is a list of strings\n",
    "data[\"genres\"] = data[\"genres\"].apply(lambda genres: encoder.transform(genres).tolist())\n",
    "data[\"favourite_genres\"] = data[\"favourite_genres\"].apply(\n",
    "    lambda genres: encoder.transform(genres).tolist())\n",
    "\n",
    "# convert encoded lists into binary arrays\n",
    "mlb = MultiLabelBinarizer()\n",
    "genres_binarized = mlb.fit_transform(data[\"genres\"])\n",
    "favourite_genres_binarized = mlb.transform(data[\"favourite_genres\"])\n",
    "\n",
    "# Combine the binary arrays with appropriate column suffixes\n",
    "X_genres_df = pd.DataFrame(genres_binarized, columns=[f'g_{col}' for col in mlb.classes_.tolist()])\n",
    "X_fav_genres_df = pd.DataFrame(favourite_genres_binarized,\n",
    "                               columns=[f'fav_{col}' for col in mlb.classes_.tolist()])\n",
    "\n",
    "# Join the binary arrays with the original DataFrame\n",
    "data = data.join(X_genres_df).join(X_fav_genres_df)\n",
    "\n",
    "# Drop the original columns\n",
    "data = data.drop(columns=[\"genres\", \"favourite_genres\"])\n",
    "\n",
    "data.head(5)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ekstrakcja labeli"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "outputs": [],
   "source": [
    "X = data.drop(columns=[\"skipped\"])\n",
    "Y = data[\"skipped\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Podział danych na zbiór treningowy i testowy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"{}\".format(Y_train.value_counts()))\n",
    "print(\"{}\".format(Y_test.value_counts()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train (RandomForestClassifier)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "print(\"TRENINGOWY\")\n",
    "y_pred = model.predict(X_train)\n",
    "print(\"Accuracy:\", accuracy_score(Y_train, y_pred))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(Y_train, y_pred))\n",
    "print(\"Classification report:\\n\", classification_report(Y_train, y_pred))\n",
    "\n",
    "print(\"TESTOWY\")\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(Y_test, y_pred))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(Y_test, y_pred))\n",
    "print(\"Classification report:\\n\", classification_report(Y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train (MLPClassifier)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001B[36m0.6525\u001B[0m       \u001B[32m0.6333\u001B[0m        \u001B[35m0.6549\u001B[0m  1.2894\n",
      "      2        \u001B[36m0.6345\u001B[0m       0.6333        \u001B[35m0.6518\u001B[0m  0.8149\n",
      "      3        \u001B[36m0.6143\u001B[0m       \u001B[32m0.6358\u001B[0m        \u001B[35m0.6511\u001B[0m  0.7097\n",
      "      4        \u001B[36m0.5954\u001B[0m       0.6146        0.6528  0.8322\n",
      "      5        \u001B[36m0.5806\u001B[0m       0.5918        0.6555  0.7092\n",
      "      6        \u001B[36m0.5720\u001B[0m       0.5781        0.6568  0.7060\n",
      "      7        \u001B[36m0.5641\u001B[0m       0.5797        0.6576  0.7221\n",
      "      8        \u001B[36m0.5589\u001B[0m       0.5797        0.6584  0.7319\n",
      "      9        \u001B[36m0.5533\u001B[0m       0.5787        0.6582  0.7057\n",
      "     10        \u001B[36m0.5487\u001B[0m       0.5852        0.6586  0.7072\n",
      "     11        \u001B[36m0.5445\u001B[0m       0.5862        0.6590  0.8168\n",
      "     12        \u001B[36m0.5408\u001B[0m       0.5883        0.6596  0.7108\n",
      "     13        \u001B[36m0.5370\u001B[0m       0.5878        0.6602  0.7200\n",
      "     14        \u001B[36m0.5326\u001B[0m       0.5873        0.6609  0.9456\n",
      "     15        \u001B[36m0.5293\u001B[0m       0.5888        0.6621  0.9899\n",
      "     16        \u001B[36m0.5254\u001B[0m       0.5878        0.6623  1.1080\n",
      "     17        \u001B[36m0.5228\u001B[0m       0.5852        0.6630  1.0362\n",
      "     18        \u001B[36m0.5198\u001B[0m       0.5867        0.6647  1.0176\n",
      "     19        \u001B[36m0.5166\u001B[0m       0.5878        0.6655  0.8157\n",
      "     20        \u001B[36m0.5139\u001B[0m       0.5842        0.6673  0.8666\n",
      "     21        \u001B[36m0.5108\u001B[0m       0.5888        0.6679  0.8581\n",
      "     22        \u001B[36m0.5084\u001B[0m       0.5893        0.6705  0.7226\n",
      "     23        \u001B[36m0.5045\u001B[0m       0.5893        0.6714  0.7579\n",
      "     24        \u001B[36m0.5013\u001B[0m       0.5893        0.6713  0.7505\n",
      "     25        \u001B[36m0.4990\u001B[0m       0.5893        0.6739  1.2104\n",
      "     26        \u001B[36m0.4955\u001B[0m       0.5893        0.6751  1.7604\n",
      "     27        \u001B[36m0.4920\u001B[0m       0.5898        0.6768  1.0797\n",
      "     28        \u001B[36m0.4892\u001B[0m       0.5923        0.6772  0.7184\n",
      "     29        \u001B[36m0.4839\u001B[0m       0.5903        0.6786  0.7143\n",
      "     30        \u001B[36m0.4822\u001B[0m       0.5933        0.6801  0.8101\n",
      "     31        \u001B[36m0.4809\u001B[0m       0.5888        0.6840  1.0238\n",
      "     32        \u001B[36m0.4766\u001B[0m       0.5943        0.6841  0.8593\n",
      "     33        \u001B[36m0.4729\u001B[0m       0.5883        0.6889  0.9911\n",
      "     34        \u001B[36m0.4700\u001B[0m       0.5928        0.6885  0.7596\n",
      "     35        \u001B[36m0.4664\u001B[0m       0.5913        0.6903  0.7256\n",
      "     36        \u001B[36m0.4629\u001B[0m       0.5873        0.6945  1.0615\n",
      "     37        \u001B[36m0.4603\u001B[0m       0.5857        0.6944  0.7689\n",
      "     38        \u001B[36m0.4572\u001B[0m       0.5857        0.6950  0.7578\n",
      "     39        \u001B[36m0.4535\u001B[0m       0.5903        0.6976  0.7078\n",
      "     40        \u001B[36m0.4510\u001B[0m       0.5888        0.6977  0.7074\n",
      "     41        \u001B[36m0.4470\u001B[0m       0.5878        0.7043  0.7478\n",
      "     42        \u001B[36m0.4433\u001B[0m       0.5878        0.7081  0.9406\n",
      "     43        \u001B[36m0.4398\u001B[0m       0.5913        0.7073  1.3854\n",
      "     44        \u001B[36m0.4373\u001B[0m       0.5883        0.7109  1.5134\n",
      "     45        \u001B[36m0.4327\u001B[0m       0.5893        0.7149  0.7074\n",
      "     46        \u001B[36m0.4280\u001B[0m       0.5893        0.7153  0.7549\n",
      "     47        \u001B[36m0.4253\u001B[0m       0.5888        0.7172  0.7049\n",
      "     48        \u001B[36m0.4228\u001B[0m       0.5878        0.7195  0.7082\n",
      "     49        \u001B[36m0.4180\u001B[0m       0.5873        0.7225  0.6993\n",
      "     50        \u001B[36m0.4162\u001B[0m       0.5862        0.7249  0.7029\n",
      "     51        \u001B[36m0.4128\u001B[0m       0.5918        0.7275  0.7104\n",
      "     52        \u001B[36m0.4090\u001B[0m       0.5918        0.7281  0.7105\n",
      "     53        \u001B[36m0.4036\u001B[0m       0.5837        0.7356  0.7227\n",
      "     54        \u001B[36m0.4014\u001B[0m       0.5938        0.7329  0.7074\n",
      "     55        \u001B[36m0.3988\u001B[0m       0.5913        0.7372  0.8941\n",
      "     56        \u001B[36m0.3940\u001B[0m       0.5888        0.7468  0.7198\n",
      "     57        \u001B[36m0.3907\u001B[0m       0.5898        0.7466  0.7159\n",
      "     58        \u001B[36m0.3882\u001B[0m       0.5953        0.7454  0.7182\n",
      "     59        \u001B[36m0.3835\u001B[0m       0.5867        0.7523  0.7011\n",
      "     60        \u001B[36m0.3821\u001B[0m       0.5888        0.7528  0.7104\n",
      "     61        \u001B[36m0.3801\u001B[0m       0.5867        0.7606  0.7061\n",
      "     62        \u001B[36m0.3736\u001B[0m       0.5878        0.7578  0.7069\n",
      "     63        \u001B[36m0.3712\u001B[0m       0.5908        0.7592  1.2019\n",
      "     64        \u001B[36m0.3655\u001B[0m       0.5903        0.7663  1.1545\n",
      "     65        \u001B[36m0.3654\u001B[0m       0.5883        0.7683  1.4419\n",
      "     66        \u001B[36m0.3637\u001B[0m       0.5857        0.7734  1.1482\n",
      "     67        \u001B[36m0.3587\u001B[0m       0.5817        0.7841  1.0877\n",
      "     68        0.3605       0.5933        0.7725  0.7197\n",
      "     69        \u001B[36m0.3547\u001B[0m       0.5867        0.7851  0.9259\n",
      "     70        \u001B[36m0.3500\u001B[0m       0.5938        0.7851  0.7071\n",
      "     71        \u001B[36m0.3459\u001B[0m       0.5832        0.7968  0.7249\n",
      "     72        \u001B[36m0.3413\u001B[0m       0.5862        0.7974  0.7076\n",
      "     73        0.3426       0.5953        0.7924  0.7008\n",
      "     74        \u001B[36m0.3389\u001B[0m       0.5812        0.8103  0.7919\n",
      "     75        0.3418       0.5903        0.7986  0.9033\n",
      "     76        0.3425       0.5817        0.8073  0.7186\n",
      "     77        \u001B[36m0.3326\u001B[0m       0.5938        0.8024  0.7310\n",
      "     78        \u001B[36m0.3276\u001B[0m       0.5918        0.8058  0.7036\n",
      "     79        \u001B[36m0.3225\u001B[0m       0.5913        0.8134  0.7209\n",
      "     80        0.3257       0.5898        0.8181  0.7100\n",
      "     81        0.3268       0.5817        0.8215  0.7065\n",
      "     82        \u001B[36m0.3173\u001B[0m       0.5852        0.8318  0.7131\n",
      "     83        0.3196       0.5852        0.8294  0.7064\n",
      "     84        \u001B[36m0.3144\u001B[0m       0.5822        0.8270  0.7195\n",
      "     85        0.3190       0.5731        0.8430  0.7074\n",
      "     86        0.3199       0.5883        0.8369  0.8659\n",
      "     87        \u001B[36m0.3066\u001B[0m       0.5873        0.8307  0.7223\n",
      "     88        0.3135       0.5792        0.8358  0.7187\n",
      "     89        \u001B[36m0.3020\u001B[0m       0.5797        0.8545  0.7075\n",
      "     90        0.3085       0.5812        0.8423  0.7091\n",
      "     91        0.3085       0.5832        0.8444  0.7152\n",
      "     92        \u001B[36m0.2935\u001B[0m       0.5797        0.8594  0.7078\n",
      "     93        0.3026       0.5842        0.8569  0.7196\n",
      "     94        \u001B[36m0.2916\u001B[0m       0.5817        0.8459  0.7176\n",
      "     95        0.2990       0.5731        0.8813  0.7076\n",
      "     96        0.3015       0.5776        0.8740  0.7074\n",
      "     97        \u001B[36m0.2860\u001B[0m       0.5776        0.8550  0.7121\n",
      "     98        0.2953       0.5776        0.8742  0.7144\n",
      "     99        \u001B[36m0.2787\u001B[0m       0.5807        0.8800  0.7144\n",
      "    100        0.2897       0.5746        0.8799  0.7109\n"
     ]
    },
    {
     "data": {
      "text/plain": "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n  module_=ClassifierModule(\n    (fc1): Linear(in_features=3532, out_features=7000, bias=True)\n    (dropout): Dropout(p=0.5, inplace=False)\n    (output): Linear(in_features=7000, out_features=2, bias=True)\n  ),\n)"
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ClassifierModule(nn.Module):\n",
    "  def __init__(self, num_inputs=3532, num_hidden=10, num_outputs=1):\n",
    "    super(ClassifierModule, self).__init__()\n",
    "\n",
    "    self.layer1 = nn.Linear(num_inputs, num_hidden)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.layer2 = nn.Linear(num_hidden, num_outputs)\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.layer1(x)\n",
    "    x = self.relu(x)\n",
    "    x = self.layer2(x)\n",
    "    x = self.sigmoid(x)\n",
    "    return x\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    ClassifierModule,\n",
    "    max_epochs=20,\n",
    "    lr=0.1,\n",
    "    optimizer__momentum=0.9,\n",
    "    verbose=0,\n",
    "    train_split=False,\n",
    ")\n",
    "\n",
    "params = {\n",
    "  'lr': [0.05, 0.1],\n",
    "  'module__num_hidden': [1, 3],\n",
    "  'optimizer__nesterov': [False, True],\n",
    "}\n",
    "\n",
    "mlpc_grid = GridSearchCV(net, params, refit=False, cv=3, scoring='accuracy', verbose=2)\n",
    "\n",
    "# mlpc_grid = GridSearchCV(MLPClassifier(), {\n",
    "#   'hidden_layer_sizes': [(3), (3, 3)],\n",
    "#   'activation': ['relu'],\n",
    "#   'solver': ['adam'],\n",
    "#   'learning_rate': ['constant'],\n",
    "# }, n_jobs=-1, cv=ms.KFold(shuffle=True), verbose=10)\n",
    "mlpc_grid.fit(X, Y)\n",
    "df = pd.DataFrame(mlpc_grid.cv_results_)\n",
    "df.drop(\n",
    "  columns=[\"split0_test_score\", \"split1_test_score\", \"split2_test_score\", \"split3_test_score\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CALOSC\n",
      "Accuracy: 0.8338224876024694\n",
      "Confusion matrix:\n",
      " [[5339  921]\n",
      " [ 721 2900]]\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.87      6260\n",
      "           1       0.76      0.80      0.78      3621\n",
      "\n",
      "    accuracy                           0.83      9881\n",
      "   macro avg       0.82      0.83      0.82      9881\n",
      "weighted avg       0.84      0.83      0.83      9881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"TRENINGOWY\")\n",
    "y_pred = mlpc_grid.predict(X_train)\n",
    "print(\"Accuracy:\", accuracy_score(Y_train, y_pred))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(Y_train, y_pred))\n",
    "print(\"Classification report:\\n\", classification_report(Y_train, y_pred))\n",
    "\n",
    "print(\"TESTOWY\")\n",
    "y_pred = mlpc_grid.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(Y_test, y_pred))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(Y_test, y_pred))\n",
    "print(\"Classification report:\\n\", classification_report(Y_test, y_pred))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3532)\n",
      "[0]\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
